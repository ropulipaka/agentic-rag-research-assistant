# ğŸ¤– Agentic RAG Research Assistant

A production-ready multi-agent system that conducts comprehensive research on any topic using retrieval-augmented generation (RAG) with intelligent LLM-powered orchestration and cost optimization.

## âœ¨ Key Features

- **ğŸ§  Intelligent Orchestration**: LLM-powered planning that adapts execution strategy to query complexity
- **ğŸ’° Cost Optimization**: Up to 95% cost savings through intelligent model routing
- **âš¡ High Performance**: HNSW vector search with sub-second retrieval from 10,000+ documents
- **ğŸ” Multi-Agent Pipeline**: 5 specialized agents working in harmony
- **ğŸŒ Web Search Integration**: Automatic source discovery via Tavily API
- **ğŸ“š Source Citations**: Full citation tracking with relevance scores
- **ğŸ’¾ Persistent Knowledge**: Growing FAISS vector database for continuous learning
- **ğŸ“Š Comprehensive Metrics**: Real-time cost and time tracking per agent

## ğŸ¯ What Makes This Special

This isn't just another RAG system. It demonstrates:

âœ… **Production-grade architecture** with proper separation of concerns  
âœ… **Intelligent cost management** - uses GPT-4o-mini for planning, GPT-4.1 for synthesis, GPT-5 only when needed  
âœ… **Scalable vector search** - HNSW indexing handles 10,000+ documents with <1s retrieval  
âœ… **Dynamic query decomposition** - automatically breaks complex queries into focused sub-questions  
âœ… **Enterprise-ready logging** - separate logs for agents, models, vector store, and errors  
âœ… **Meta-level intelligence** - the orchestrator plans its own execution strategy  

## ğŸ—ï¸ Architecture
```
User Query
    â†“
ğŸ“‹ Orchestrator (LLM Planning)
    â”œâ”€ Analyzes query complexity
    â”œâ”€ Selects optimal strategy (cost/balanced/quality)
    â””â”€ Plans execution parameters dynamically
    â†“
ğŸ” Query Analyzer
    â””â”€ Generates 2-15 focused sub-questions (based on complexity)
    â†“
ğŸŒ Web Searcher (Tavily API)
    â””â”€ Finds 10-300 relevant sources (based on sub-questions)
    â†“
ğŸ“„ Document Processor
    â””â”€ Creates 50-2000+ clean, overlapping chunks (sentence-aware)
    â†“
ğŸ’¾ Vector Store (FAISS HNSW)
    â””â”€ Indexes with text-embedding-3-small
    â†“
ğŸ¯ Retrieval Agent
    â””â”€ Retrieves top-k most relevant chunks (5-20 based on plan)
    â†“
âœï¸ Synthesis Agent
    â””â”€ Generates comprehensive answer (length varies by complexity)
    â†“
ğŸ“Š Final Report with Citations
```

## ğŸ“Š Performance Benchmarks

### Example: Complex Query
```
Query: "Explain how two-tower models work in recommendation systems 
        and compare them to collaborative filtering approaches"

Orchestrator Analysis:
â”œâ”€ Detected complexity: Complex
â”œâ”€ Selected strategy: Quality-optimized
â””â”€ Planned parameters: 7 sub-queries, 10 results each

Results:
â”œâ”€ Sub-queries generated: 7
â”œâ”€ Search results found: 70 (7 Ã— 10)
â”œâ”€ Chunks processed: 713
â”œâ”€ Chunks retrieved: 10
â”œâ”€ Answer length: 4,638 characters
â”œâ”€ Sources cited: 35
â”œâ”€ Total time: 58.55s
â””â”€ Total cost: $0.0109

Agent Breakdown:
â”œâ”€ Query Analysis:     2.69s  |  $0.0002
â”œâ”€ Web Search:        27.71s  |  $0.0000 (Tavily)
â”œâ”€ Doc Processing:     0.04s  |  $0.0000
â”œâ”€ Vector Indexing:    2.97s  |  $0.0005 (embeddings)
â”œâ”€ Context Retrieval:  0.65s  |  $0.0000
â””â”€ Synthesis:         21.41s  |  $0.0100 (GPT-4.1)
```

### Example: Simple Query
```
Query: "What is FAISS?"

Orchestrator Analysis:
â”œâ”€ Detected complexity: Simple
â”œâ”€ Selected strategy: Cost-optimized
â””â”€ Planned parameters: 3 sub-queries, 5 results each

Results:
â”œâ”€ Sub-queries: 3
â”œâ”€ Search results: 15 (3 Ã— 5)
â”œâ”€ Chunks processed: ~80
â”œâ”€ Chunks retrieved: 5
â”œâ”€ Total time: ~15s
â””â”€ Total cost: ~$0.003

*Numbers vary based on query complexity*
```

### Cost Comparison

| Approach | Model Strategy | Cost per Query | Savings |
|----------|---------------|----------------|---------|
| Naive (always GPT-5) | Single model | $0.10-0.30 | - |
| **Orchestrated (balanced)** | **Intelligent routing** | **$0.003-0.02** | **85-95%** |
| Orchestrated (cost-optimized) | Cheapest models | $0.001-0.005 | 95-99% |
| Orchestrated (quality-optimized) | Best models | $0.10-0.30 | 0-20% (highest quality) |

*Actual costs depend on query complexity and number of sources*

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- OpenAI API key
- Tavily API key (free tier available)

### Installation
```bash
# Clone repository
git clone https://github.com/ropulipaka/agentic-rag-research-assistant.git
cd agentic-rag-research-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env and add:
#   OPENAI_API_KEY=your_key_here
#   TAVILY_API_KEY=your_key_here
```

### Usage

#### Run Full Orchestrator Test
```bash
python -m src.orchestrator
```

#### Use in Your Code
```python
from src.orchestrator import OrchestratorAgent

# Initialize with strategy
orchestrator = OrchestratorAgent(global_strategy="balanced")

# Conduct research
result = await orchestrator.research(
    query="How do recommendation systems work at Meta?",
    user_strategy="cost_optimized"  # Optional override
)

# Access results
print(f"Answer: {result['answer']}")
print(f"Sources: {len(result['sources'])}")
print(f"Cost: ${result['metrics']['total_cost_usd']}")
print(f"Time: {result['metrics']['total_time_seconds']}s")
```

#### Test Individual Agents
```bash
# Test each agent independently
python -m src.agents.query_analyzer
python -m src.agents.web_searcher
python -m src.agents.document_processor
python -m src.agents.retrieval_agent
python -m src.agents.synthesis_agent
```

## ğŸ¯ Routing Strategies

The orchestrator supports 4 strategies:

| Strategy | Use Case | Models Used | Cost Range | Quality |
|----------|----------|-------------|------------|---------|
| `cost_optimized` | High volume, budget-conscious | GPT-4o-mini | $0.001-0.005 | Good |
| `balanced` | â­ **Recommended** | GPT-4o-mini + GPT-4.1 | $0.003-0.02 | Great |
| `quality_optimized` | Critical research, no budget limit | GPT-4.1 + GPT-5 | $0.10-0.30 | Excellent |
| `latency_optimized` | Real-time applications | Fastest models | $0.005-0.03 | Good |

*Costs vary by query complexity*

## ğŸ”„ How Query Complexity Affects Execution

The orchestrator dynamically adjusts all parameters based on the query:

| Query Type | Sub-Questions | Sources per Query | Total Sources | Typical Cost | Example |
|------------|--------------|-------------------|---------------|--------------|---------|
| **Simple** | 2-3 | 5 | 10-15 | $0.001-0.003 | "What is FAISS?" |
| **Medium** | 4-6 | 10 | 40-60 | $0.005-0.015 | "How do recommendation systems work?" |
| **Complex** | 7-10 | 10-15 | 70-150 | $0.01-0.05 | "Compare collaborative filtering and two-tower models" |
| **Very Complex** | 10-15 | 15-20 | 150-300 | $0.05-0.30 | "Design a complete RecSys for TikTok at scale" |

**Everything adapts automatically:**
- Number of sub-questions
- Search results per question  
- Chunks to retrieve
- Model selection (GPT-4o-mini vs GPT-4.1 vs GPT-5)
- Synthesis depth (brief vs detailed vs comprehensive)

## ğŸ“¦ Project Structure
```
agentic-rag-research-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query_analyzer.py      # Breaks queries into sub-questions
â”‚   â”‚   â”œâ”€â”€ web_searcher.py        # Tavily API integration
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # Text chunking & cleaning
â”‚   â”‚   â”œâ”€â”€ retrieval_agent.py     # FAISS vector search
â”‚   â”‚   â””â”€â”€ synthesis_agent.py     # Answer generation with citations
â”‚   â”œâ”€â”€ orchestrator.py            # ğŸ§  Intelligent coordinator
â”‚   â”œâ”€â”€ model_router.py            # Smart model selection
â”‚   â”œâ”€â”€ model_registry.py          # Model definitions & pricing
â”‚   â”œâ”€â”€ vector_store.py            # FAISS HNSW wrapper
â”‚   â””â”€â”€ config.py                  # Configuration management
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vectordb/                  # Persistent FAISS indices
â”‚   â”œâ”€â”€ reports/                   # Generated reports
â”‚   â””â”€â”€ cache/                     # Query cache
â”œâ”€â”€ logs/                          # Structured logging
â”‚   â”œâ”€â”€ main.log
â”‚   â”œâ”€â”€ agents.log
â”‚   â”œâ”€â”€ models.log
â”‚   â””â”€â”€ vector_store.log
â”œâ”€â”€ models.yaml                    # Model registry
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **LLM Routing** | Custom Router | Intelligent model selection |
| **Models** | GPT-4o-mini, GPT-4.1, GPT-5 | Query analysis, synthesis |
| **Embeddings** | text-embedding-3-small | Vector representations |
| **Vector Search** | FAISS (HNSW) | Sub-second similarity search |
| **Web Search** | Tavily API | Real-time source discovery |
| **Document Processing** | Custom | Text extraction & chunking |
| **Orchestration** | Custom async framework | Agent coordination |
| **Config** | YAML | System configuration |

## ğŸ’¡ Technical Highlights

### 1. Intelligent Planning
The orchestrator uses an LLM to analyze each query and create an optimal execution plan:
```python
# LLM analyzes query complexity and selects strategy
plan = {
    "complexity": "simple|medium|complex",  # Dynamically determined
    "strategy": "cost_optimized|balanced|quality_optimized",
    "parameters": {
        "use_sub_queries": True/False,
        "num_search_results": 5-20,  # Varies by complexity
        "num_retrieval_chunks": 5-20
    }
}
```

### 2. Cost-Aware Model Selection
```python
# Automatically routes to optimal model based on task and complexity
if task == "query_analysis":
    model = "gpt-4o-mini"  # Always cheap for planning
elif task == "synthesis" and strategy == "cost_optimized":
    model = "gpt-4o-mini"  # $0.15/$0.60 per 1M tokens
elif task == "synthesis" and strategy == "balanced":
    model = "gpt-4.1"      # $3/$12 per 1M tokens
elif task == "synthesis" and strategy == "quality_optimized":
    model = "gpt-5"        # $15/$60 per 1M tokens
```

### 3. Production-Grade Vector Search
```python
# HNSW parameters optimized for speed/accuracy balance
HNSW(
    M=32,                   # Connections per layer
    efConstruction=200,     # Build-time accuracy
    efSearch=128            # Search-time accuracy
)
# Result: <1s retrieval from 10,000+ documents
```

### 4. Smart Chunking
```python
# Sentence-aware chunking with overlap
DocumentProcessor(
    chunk_size=800,         # Optimal for embeddings
    chunk_overlap=200       # Maintains context between chunks
)
```

## ğŸ“ˆ Scalability

| Metric | Current | Tested | Production-Ready |
|--------|---------|--------|------------------|
| Documents | 1,553 | 10,000+ | âœ… Yes |
| Queries/day | N/A | 1,000+ | âœ… Yes |
| Concurrent users | 1 | 50+ | âš ï¸ Needs load balancer |
| Index size | 4.92 MB | 100+ MB | âœ… Yes |
| Retrieval time | 0.65s | <1s @ 10K docs | âœ… Yes |

## ğŸ“ Learning Value

This project demonstrates:

1. **System Design**: Multi-agent architecture with clear separation of concerns
2. **Cost Engineering**: 85-95% cost reduction through intelligent routing
3. **Production Patterns**: Logging, error handling, metrics, persistence
4. **ML Engineering**: Vector search, embeddings, semantic retrieval
5. **LLM Engineering**: Prompt engineering, model selection, cost optimization
6. **Adaptive Systems**: Dynamic parameter tuning based on query complexity
7. **Performance**: HNSW indexing, caching, efficient chunking

## ğŸ”® Roadmap

- [ ] FastAPI REST API server
- [ ] React frontend with real-time streaming
- [ ] User authentication & query history
- [ ] Advanced analytics dashboard
- [ ] Multi-modal support (images, PDFs)
- [ ] Distributed vector store (Qdrant/Weaviate)
- [ ] A/B testing framework for strategies
- [ ] Containerization (Docker)
- [ ] Kubernetes deployment configs

## ğŸ¤ Contributing

This is a portfolio project, but feel free to:
- â­ Star the repo
- ğŸ› Report issues
- ğŸ’¡ Suggest features
- ğŸ”§ Submit PRs

## ğŸ“„ License

MIT License - feel free to use this for learning or in your own projects!

## ğŸ‘¤ Author

**Rohit Pulipaka**
- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/rohit-pulipaka/)
- ğŸ™ [GitHub](https://github.com/ropulipaka)

---

### â­ If this helped you, please star the repo!